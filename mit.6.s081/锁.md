# 锁和多进程

## 锁

#### 为什么使用锁？

多核cpu带来性能提升的同时，同时带来并行访问共享数据结果的问题。

如一个核在读取数据，另一个核在写入数据，需要使用锁来协调对于共享数据的更新，以**确保数据的一致性**

该机制的**矛盾之处**，使用**锁降低了并行的性能**。

#### 锁的作用有：

打包多个操作，使它们具有原子性

避免丢失更新，维护共享数据结构的不变性。 --当我们说锁保护数据时，我们实际上是指锁保护适用于数据的某些不变量集合。

#### 锁是如何避免race condition的？

​	锁 拥有两个方法，获取 和释放

​	在获取与释放之间的代码被称作 临界区  其中的多条指令，它们要么会一起执行，要么一条也不会执行。

#### 临界区和临界资源的区别：

​	临界区是一段访问临界资源的代码

​	临界资源是 仅允许一个进程使用的共享资源



锁序列化了代码的执行。

#### 什么时候使用锁？

锁限制了并发性，也限制了性能。

保守同时也是非常简单的规则：如果两个进程访问了一个共享的数据结构，并且其中一个进程会更新共享的数据结构，那么就需要对于这个共享的数据结构加锁。

**锁应该与操作而不是数据关联**，自动加锁在某些场景下会出问题。

想**获得更高的性能，需要拆分数据结构和锁**。如果只有一个big kernel lock，那么操作系统只能被一个CPU运行。需要将数据结构和锁进行拆分

### 死锁

当有多个锁时，锁获取的顺序不做规范时，可能会造成死锁。

解决办法： 对锁进行排序，所有的操作都必须以相同的顺序获取锁。

总是先获取排序靠前的目录的锁，再获取排序靠后的目录的锁。如果对于所有的锁有了一个全局的排序，这里的死锁就不会出现了。



#### 自旋锁的实现（spinlock）

锁基本特征：只有一个进程可以获取锁，在任何时间点都不能有超过一个锁的持有者。

主要难点在于：

​	acquire 接口  **该接口里面有一个死循环**，循环中判断锁对象的locked字段是否为0，如果为0那表明当前锁没有持有者，当前对于acquire的调用可以获取锁。之后我们通过设置锁对象的locked字段为1来获取锁。最后返回。若锁的locked字段不为0，那么当前对于acquire的调用就**不能获取锁，程序会一直spin**。也就是说，**程序在循环中不停的重复执行**，直到锁的持有者调用了release并将锁对象的locked设置为0。

问题：在这个实现里 两个进程可能同时读到锁的locked字段为0。当cpu1 和cpu2 同时查看locked时 但都未改变该字段时，在这个时间差内，它们都acquire了锁。这样违背了锁的特性。

为了解决这里的问题并得到一个正确的锁的实现方式，其实有多种方法，但是最常见的方法是**依赖于一个特殊的硬件指令**。这个特殊的硬件指令会保证一次test-and-set操作的原子性。在RISC-V上，这个特殊的指令就是**amoswap**（atomic memory swap）。这个指令接收3个参数，分别是address，寄存器r1，寄存器r2。这条指令会先锁定住address，将address中的数据保存在一个临时变量中（tmp），之后将r1中的数据写入到地址中，之后再将保存在临时变量中的数据写入到r2中，最后再对于地址解锁。

通过这里的加锁，可以确保address中的数据存放于r2，而r1中的数据存放于address中，并且这一系列的指令打包具备原子性。大多数的处理器都有这样的硬件指令，因为这是一个实现锁的方便的方式。这里我们通过将一个软件锁转变为硬件锁最终实现了原子性。

此处注明：

多个处理器共用一个内存控制器，内存控制器可以支持这里的操作，比如给一个特定的地址加锁，然后让一个处理器执行2-3个指令，然后再解锁。因为所有的处理器都需要通过这里的内存控制器完成读写，所以内存控制器可以对操作进行排序和加锁。

如果内存位于一个共享的总线上，那么需要总线控制器（bus arbiter）来支持。总线控制器需要以原子的方式执行多个内存操作。

如果处理器有缓存，那么缓存一致性协议会确保对于持有了我们想要更新的数据的cache line只有一个写入者，相应的处理器会对cache line加锁，完成两个操作。

**硬件原子操作的实现**可以有很多种方法。但是基本上都是对于**地址加锁，读出数据，写入新数据，然后再返回旧数据**

![image-20230202155528663](C:\Users\qq130\AppData\Roaming\Typora\typora-user-images\image-20230202155528663.png)

![image-20230202155511312](C:\Users\qq130\AppData\Roaming\Typora\typora-user-images\image-20230202155511312.png)

![image-20230202155804888](C:\Users\qq130\AppData\Roaming\Typora\typora-user-images\image-20230202155804888.png)

如果锁没有被持有，那么锁对象的locked字段会是0，如果locked字段等于0，我们调用test-and-set将1写入locked字段，并且返回locked字段之前的数值0。如果返回0，那么意味着没有人持有锁，循环结束。如果locked字段之前是1，那么这里的流程是，先将之前的1读出，然后写入一个新的1，但是这不会改变任何数据，因为locked之前已经是1了。之后__sync_lock_test_and_set会返回1，表明锁之前已经被人持有了，这样的话，判断语句不成立，程序会持续循环（spin），直到锁的locked字段被设置回0。

问题：**为什么release函数中不直接使用一个store指令将锁的locked字段写为0。**

答 因为其他的处理器可能会向locked字段写入1，或者写入0，而且经常会认为一个store指令是一个原子操作，但实际并不总是这样，这取决于具体的实现。



spinlock需要处理两类并发，**一类是不同CPU之间的并发**，一类是**相同CPU上中断和普通程序之间的并发**

**memory ordering**：假设我们先通过将locked字段设置为1来获取锁，之后对x加1，最后再将locked字段设置0来释放锁。下面将会是在CPU上执行的指令流：locked <- 1  x <- 1 locked <- 0

但是编译器或者处理器可能会重排指令以获得更好的性能。对于上面的串行指令流，如果将x<-x+1移到locked<-0之后可以吗？这会改变指令流的正确性吗？

并不会，因为x和锁完全相互独立，它们之间没有任何关联。在串行下这种优化 是不会对程序的执行产生影响

但是在并发执行时，指令重新排序在并发场景是错误的。为了禁止，或者说为了告诉编译器和硬件不要这样做，我们需要使用memory fence或者叫做synchronize指令，来确定指令的移动范围。对于synchronize指令，任何在它之前的load/store指令，都不能移动到它之后。锁的acquire和release函数都包含了synchronize指令。



acquire和release都有自己的界限（注，也就是__sync_synchronize函数的调用点）。所以发生在锁acquire之前的指令不会被移到acquire的__sync_synchronize函数调用之后，这是一个界限。在锁的release函数中有另一个界限。所以在第一个界限之前的指令会一直在这个界限之前，在两个界限之间的指令会保持在两个界限之间，在第二个界限之后的指令会保持在第二个界限之后。

#### 如何保证acquire 和 release的原子性？





block cache使用的是sleep lock。sleep lock区别于一个常规的spinlock。我们先看来一下sleep lock。

![img](https://906337931-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-MHZoT2b_bcLghjAOPsJ%2F-MRr3gfIDCTMvY7N6U4V%2F-MRteSLOezqXvcfZPyjL%2Fimage.png?alt=media&token=356d75c6-da32-4a4b-ac9b-b3361fdbb6ee)

首先是acquiresleep函数，它用来获取sleep lock。函数里首先获取了一个普通的spinlock，这是与sleep lock关联在一起的一个锁。之后，如果sleep lock被持有，那么就进入sleep状态，并将自己从当前CPU调度开。

既然sleep lock是基于spinlock实现的，为什么对于block cache，我们使用的是sleep lock而不是spinlock？

对于spinlock有很多限制，其中之一是加锁时中断必须要关闭。所以如果使用spinlock的话，当我们对block cache做操作的时候需要持有锁，那么我们就永远也不能从磁盘收到数据。或许另一个CPU核可以收到中断并读到磁盘数据，但是如果我们只有一个CPU核的话，我们就永远也读不到数据了。出于同样的原因，也不能在持有spinlock的时候进入sleep状态（注，详见13.1）。所以这里我们使用sleep lock。sleep lock的优势就是，我们可以在持有锁的时候不关闭中断。我们可以在磁盘操作的过程中持有锁，我们也可以长时间持有锁。当我们在等待sleep lock的时候，我们并没有让CPU一直空转，我们通过sleep将CPU出让出去了